{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_LZqwSHqtr5"
   },
   "source": [
    "*유의사항*. *구글 코랩에서 실행하셔야 합니다.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18573,
     "status": "ok",
     "timestamp": 1704072467330,
     "user": {
      "displayName": "윤동언",
      "userId": "18223722253991517958"
     },
     "user_tz": -540
    },
    "id": "cpUy7yiyXA-7",
    "outputId": "a4347e7c-07c8-410e-87e0-79e11a69543c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 300,
     "status": "ok",
     "timestamp": 1704072639771,
     "user": {
      "displayName": "윤동언",
      "userId": "18223722253991517958"
     },
     "user_tz": -540
    },
    "id": "IRm4NNjgXD_b",
    "outputId": "8601dcb0-2ba0-4a73-abaa-d006ac9f0850"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13802,
     "status": "ok",
     "timestamp": 1704072708576,
     "user": {
      "displayName": "윤동언",
      "userId": "18223722253991517958"
     },
     "user_tz": -540
    },
    "id": "JKp0TqFrpPvk",
    "outputId": "7a5bafd5-6780-45e6-a9c5-9629c890d5bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastapi\n",
      "  Downloading fastapi-0.108.0-py3-none-any.whl (92 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m994.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (1.10.13)\n",
      "Collecting starlette<0.33.0,>=0.29.0 (from fastapi)\n",
      "  Downloading starlette-0.32.0.post1-py3-none-any.whl (70 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.0/70.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions>=4.8.0 (from fastapi)\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.33.0,>=0.29.0->fastapi) (3.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.33.0,>=0.29.0->fastapi) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.33.0,>=0.29.0->fastapi) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.33.0,>=0.29.0->fastapi) (1.2.0)\n",
      "Installing collected packages: typing-extensions, starlette, fastapi\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lida 0.0.10 requires kaleido, which is not installed.\n",
      "lida 0.0.10 requires python-multipart, which is not installed.\n",
      "lida 0.0.10 requires uvicorn, which is not installed.\n",
      "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fastapi-0.108.0 starlette-0.32.0.post1 typing-extensions-4.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11453,
     "status": "ok",
     "timestamp": 1704072754281,
     "user": {
      "displayName": "윤동언",
      "userId": "18223722253991517958"
     },
     "user_tz": -540
    },
    "id": "1RJIiI-Wpj64",
    "outputId": "d57c34cd-5eea-47d8-ff2b-9df6eb0e3084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaleido\n",
      "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: kaleido\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lida 0.0.10 requires python-multipart, which is not installed.\n",
      "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed kaleido-0.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5268,
     "status": "ok",
     "timestamp": 1704072773996,
     "user": {
      "displayName": "윤동언",
      "userId": "18223722253991517958"
     },
     "user_tz": -540
    },
    "id": "zDDkRG7OptA5",
    "outputId": "d142db7f-4ef9-4622-eb90-2d3d90dfdfb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-multipart\n",
      "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m838.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: python-multipart\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed python-multipart-0.0.6\n"
     ]
    }
   ],
   "source": [
    "!pip install python-multipart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6605,
     "status": "ok",
     "timestamp": 1704072833989,
     "user": {
      "displayName": "윤동언",
      "userId": "18223722253991517958"
     },
     "user_tz": -540
    },
    "id": "z7_Exm48p6aG",
    "outputId": "88ca58f8-dc3a-4158-d41c-04a1dc7c8903"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting uvicorn\n",
      "  Downloading uvicorn-0.25.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m772.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
      "Collecting h11>=0.8 (from uvicorn)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (4.9.0)\n",
      "Installing collected packages: h11, uvicorn\n",
      "Successfully installed h11-0.14.0 uvicorn-0.25.0\n"
     ]
    }
   ],
   "source": [
    "!pip install uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 26525,
     "status": "ok",
     "timestamp": 1704072876442,
     "user": {
      "displayName": "윤동언",
      "userId": "18223722253991517958"
     },
     "user_tz": -540
    },
    "id": "iA-B7VVBXOUh",
    "outputId": "bf592e13-41e8-4304-e956-c9b96d681e9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Downloading roboflow-1.1.14-py3-none-any.whl (68 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting certifi==2023.7.22 (from roboflow)\n",
      "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting chardet==4.0.0 (from roboflow)\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting idna==2.10 (from roboflow)\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.23.5)\n",
      "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n",
      "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
      "Collecting pyparsing==2.4.7 (from roboflow)\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
      "Collecting python-dotenv (from roboflow)\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
      "Collecting supervision (from roboflow)\n",
      "  Downloading supervision-0.17.1-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
      "Collecting requests-toolbelt (from roboflow)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-magic (from roboflow)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.46.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
      "Requirement already satisfied: scipy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.4)\n",
      "Installing collected packages: python-magic, python-dotenv, pyparsing, opencv-python-headless, idna, cycler, chardet, certifi, supervision, requests-toolbelt, roboflow\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.1.1\n",
      "    Uninstalling pyparsing-3.1.1:\n",
      "      Successfully uninstalled pyparsing-3.1.1\n",
      "  Attempting uninstall: opencv-python-headless\n",
      "    Found existing installation: opencv-python-headless 4.8.1.78\n",
      "    Uninstalling opencv-python-headless-4.8.1.78:\n",
      "      Successfully uninstalled opencv-python-headless-4.8.1.78\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.6\n",
      "    Uninstalling idna-3.6:\n",
      "      Successfully uninstalled idna-3.6\n",
      "  Attempting uninstall: cycler\n",
      "    Found existing installation: cycler 0.12.1\n",
      "    Uninstalling cycler-0.12.1:\n",
      "      Successfully uninstalled cycler-0.12.1\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 5.2.0\n",
      "    Uninstalling chardet-5.2.0:\n",
      "      Successfully uninstalled chardet-5.2.0\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2023.11.17\n",
      "    Uninstalling certifi-2023.11.17:\n",
      "      Successfully uninstalled certifi-2023.11.17\n",
      "Successfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 pyparsing-2.4.7 python-dotenv-1.0.0 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.14 supervision-0.17.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "certifi",
         "cycler",
         "pyparsing"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in blind-man-13 to yolov5pytorch:: 100%|██████████| 313561/313561 [00:07<00:00, 41122.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to blind-man-13 in yolov5pytorch:: 100%|██████████| 9449/9449 [00:01<00:00, 5118.64it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"XzjYCXE480gEXboQJ53V\")\n",
    "project = rf.workspace(\"bigp\").project(\"blind-man\")\n",
    "dataset = project.version(13).download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWM_BsXro8kF"
   },
   "source": [
    "# 새 섹션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1704072935025,
     "user": {
      "displayName": "윤동언",
      "userId": "18223722253991517958"
     },
     "user_tz": -540
    },
    "id": "rMTjTkeMXVIf"
   },
   "outputs": [],
   "source": [
    "# 필요 라이브러리 불러오기\n",
    "import glob\n",
    "\n",
    "# 데이터셋과 Yolo5모델(.pt) 저장을 위한 DATA_PATH, TRAIN_PATH, VALIDATION_PATH 지정\n",
    "# DATA_PATH(blind-man-버전), TRAIN_PATH(blind-man-버전/train),  VALIDATION_PATH(blind-man-버전/valid) 지정\n",
    "DATA_PATH = '/content/blind-man-13'\n",
    "TRAIN_PATH = \"/content/blind-man-13/train\"\n",
    "VALIDATION_PATH =  \"/content/blind-man-13/valid\"\n",
    "\n",
    "# glob 모듈의 glob 함수을 통해  조건에 맞는 파일명을 리스트 형식으로 저장\n",
    "# train_image_list에 train 폴더의 image리스트 저장\n",
    "# validation_image_list에 VALIDATION 폴더의 image리스트 저장\n",
    "train_image_list = glob.glob(TRAIN_PATH+\"/images/*.jpg\")\n",
    "validation_image_list = glob.glob(VALIDATION_PATH+\"/images/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1704072986793,
     "user": {
      "displayName": "윤동언",
      "userId": "18223722253991517958"
     },
     "user_tz": -540
    },
    "id": "nS4Gqkq0XsQc",
    "outputId": "d0bde8c8-996c-45e4-db2c-67f74470ee39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터(이미지) 개수 : 3743\n",
      "검증 데이터(이미지) 개수 : 977\n"
     ]
    }
   ],
   "source": [
    "print(\"학습 데이터(이미지) 개수 : \" + str(len(train_image_list)))\n",
    "print(\"검증 데이터(이미지) 개수 : \" + str(len(validation_image_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1704073442016,
     "user": {
      "displayName": "윤동언",
      "userId": "18223722253991517958"
     },
     "user_tz": -540
    },
    "id": "c9VGkf3tXvIs"
   },
   "outputs": [],
   "source": [
    "# \"blind-man-버전\"폴더 즉, 데이터 폴더 밑에 train.txt 파일을 생성한 후에 앞서 저장된 train_image_list 파일 리스트를 저장\n",
    "with open(DATA_PATH + '/train.txt', 'w') as f:\n",
    "    f.write('\\n'.join(train_image_list) + '\\n')\n",
    "# \"blind-man-버전\"폴더 즉, 데이터 폴더 밑에 validation.txt 파일을 생성한 후에 앞서 저장된 validation_image_list 파일 리스트를 저장\n",
    "with open(DATA_PATH + '/validation.txt', 'w') as f:\n",
    "    f.write('\\n'.join(validation_image_list) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1704073476239,
     "user": {
      "displayName": "윤동언",
      "userId": "18223722253991517958"
     },
     "user_tz": -540
    },
    "id": "iRHAiwPNX0BO",
    "outputId": "a0c5cbe9-8d49-4a7d-cb2e-85f3a41cb78a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'names': ['guide dog', 'whiteCane'], 'nc': 2, 'roboflow': {'license': 'CC BY 4.0', 'project': 'blind-man', 'url': 'https://universe.roboflow.com/bigp/blind-man/dataset/13', 'version': 13, 'workspace': 'bigp'}, 'test': '../test/images', 'train': 'blind-man-13/train/images', 'val': 'blind-man-13/valid/images'}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# yaml 데이터를 열어서(로딩) data라는 변수에 정보를 딕셔너리 형태로 저장\n",
    "with open('/content/blind-man-13/data.yaml', 'r') as f:\n",
    "  data = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "print(data)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1704073674909,
     "user": {
      "displayName": "윤동언",
      "userId": "18223722253991517958"
     },
     "user_tz": -540
    },
    "id": "AffCLChBX5Sm"
   },
   "outputs": [],
   "source": [
    "# data 변수 내에 train, val 열의 데이터를 이미지 이름 리스트 파일 정보로 변경\n",
    "data['train'] = '/content/blind-man-13/train.txt'\n",
    "data['val'] = '/content/blind-man-13/validation.txt'\n",
    "\n",
    "# 변경된 'data' dictionary 를 Yaml 파일로 변경하여 저장\n",
    "with open(DATA_PATH + '/data.yaml', 'w') as f:\n",
    "  yaml.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2710,
     "status": "ok",
     "timestamp": 1704073712457,
     "user": {
      "displayName": "윤동언",
      "userId": "18223722253991517958"
     },
     "user_tz": -540
    },
    "id": "QDIMMtCYYDcc",
    "outputId": "e6f58706-4246-4f82-dba9-00695a72378a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 16117, done.\u001b[K\n",
      "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
      "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
      "remote: Total 16117 (delta 9), reused 11 (delta 1), pack-reused 16089\u001b[K\n",
      "Receiving objects: 100% (16117/16117), 14.80 MiB | 20.17 MiB/s, done.\n",
      "Resolving deltas: 100% (11033/11033), done.\n"
     ]
    }
   ],
   "source": [
    "# github에서 yolov5 모델 불러오기\n",
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 287,
     "status": "ok",
     "timestamp": 1704073715846,
     "user": {
      "displayName": "윤동언",
      "userId": "18223722253991517958"
     },
     "user_tz": -540
    },
    "id": "f6U2ZD7lYFlM",
    "outputId": "5c19e75d-96f8-44c3-f80c-133790ce45fd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1704073718174,
     "user": {
      "displayName": "윤동언",
      "userId": "18223722253991517958"
     },
     "user_tz": -540
    },
    "id": "37Aemf_7YMBu",
    "outputId": "190846c7-166a-41e8-c3dd-ba48fec80806"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 10405,
     "status": "ok",
     "timestamp": 1704073740704,
     "user": {
      "displayName": "윤동언",
      "userId": "18223722253991517958"
     },
     "user_tz": -540
    },
    "id": "h-JslWWgYNdA",
    "outputId": "fadd3493-ac80-4578-a9c2-2c954d77f04a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gitpython>=3.1.30 (from -r requirements.txt (line 5))\n",
      "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.23.5)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.8.0.76)\n",
      "Collecting Pillow>=10.0.1 (from -r requirements.txt (line 9))\n",
      "  Downloading Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.11.4)\n",
      "Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.1.0+cu121)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.16.0+cu121)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.66.1)\n",
      "Collecting ultralytics>=8.0.147 (from -r requirements.txt (line 18))\n",
      "  Downloading ultralytics-8.0.231-py3-none-any.whl (663 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.2/663.2 kB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (1.5.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.12.2)\n",
      "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (67.7.2)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30->-r requirements.txt (line 5))\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2023.7.22)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.1.0)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.147->-r requirements.txt (line 18)) (9.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.3.post1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from cycler>=0.10->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5))\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
      "Installing collected packages: smmap, Pillow, gitdb, thop, gitpython, ultralytics\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 9.4.0\n",
      "    Uninstalling Pillow-9.4.0:\n",
      "      Successfully uninstalled Pillow-9.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Pillow-10.1.0 gitdb-4.0.11 gitpython-3.1.40 smmap-5.0.1 thop-0.1.1.post2209072238 ultralytics-8.0.231\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "PIL"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# requirements.txt에 적힌 모듈 목록 설치\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9341644,
     "status": "ok",
     "timestamp": 1704084376361,
     "user": {
      "displayName": "윤동언",
      "userId": "18223722253991517958"
     },
     "user_tz": -540
    },
    "id": "mBsF4DHQYO0B",
    "outputId": "090ac28e-d632-4049-9bf5-e92a78468d88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-01 02:10:43.593774: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-01 02:10:43.593824: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-01 02:10:43.595237: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5l.pt, cfg=, data=/content/blind-man-13/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=../camera_dedects, name=results, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "remote: Enumerating objects: 67, done.\u001b[K\n",
      "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
      "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
      "remote: Total 67 (delta 51), reused 63 (delta 51), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (67/67), 55.10 KiB | 868.00 KiB/s, done.\n",
      "From https://github.com/ultralytics/yolov5\n",
      " * [new branch]      add-format-workflow-20240101030510 -> origin/add-format-workflow-20240101030510\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
      "YOLOv5 🚀 v7.0-254-gba63208 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ../camera_dedects', view at http://localhost:6006/\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
      "100% 755k/755k [00:00<00:00, 17.4MB/s]\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5l.pt to yolov5l.pt...\n",
      "100% 89.3M/89.3M [00:00<00:00, 244MB/s]\n",
      "\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
      " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
      " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
      " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
      " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
      " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
      "Model summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
      "\n",
      "Transferred 607/613 items from yolov5l.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005), 104 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/blind-man-13/train... 3743 images, 7 backgrounds, 0 corrupt: 100% 3743/3743 [00:03<00:00, 935.76it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/blind-man-13/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/blind-man-13/validation... 977 images, 0 backgrounds, 0 corrupt: 100% 977/977 [00:02<00:00, 473.21it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/blind-man-13/validation.cache\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.24 anchors/target, 0.997 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to ../camera_dedects/results/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m../camera_dedects/results\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       0/49      9.81G    0.06916    0.02295    0.01034         31        640: 100% 234/234 [02:49<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:22<00:00,  1.39it/s]\n",
      "                   all        977       1170      0.577      0.788      0.686      0.348\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/49      11.4G    0.05084    0.01507   0.002209         33        640: 100% 234/234 [02:41<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.51it/s]\n",
      "                   all        977       1170      0.705        0.8      0.835      0.492\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/49      11.4G    0.04541     0.0127   0.002088         33        640: 100% 234/234 [02:43<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.53it/s]\n",
      "                   all        977       1170      0.837      0.937      0.889      0.474\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/49      11.4G    0.04104    0.01238   0.001678         41        640: 100% 234/234 [02:39<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:19<00:00,  1.55it/s]\n",
      "                   all        977       1170       0.87      0.906      0.918      0.538\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/49      11.4G    0.03859    0.01226   0.001318         34        640: 100% 234/234 [02:43<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:19<00:00,  1.56it/s]\n",
      "                   all        977       1170      0.885       0.94      0.927      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/49      11.4G    0.03569    0.01177   0.001367         28        640: 100% 234/234 [02:40<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:22<00:00,  1.39it/s]\n",
      "                   all        977       1170      0.864      0.875      0.879      0.533\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/49      11.4G    0.03455     0.0114   0.001023         23        640: 100% 234/234 [02:39<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.49it/s]\n",
      "                   all        977       1170      0.921      0.947      0.943      0.579\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/49      11.4G    0.03293    0.01125  0.0008768         32        640: 100% 234/234 [02:42<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.51it/s]\n",
      "                   all        977       1170      0.918      0.956      0.944      0.605\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/49      11.4G    0.03189    0.01094  0.0007341         28        640: 100% 234/234 [02:40<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.54it/s]\n",
      "                   all        977       1170      0.934      0.952      0.959      0.626\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/49      11.4G    0.03052    0.01066  0.0006832         21        640: 100% 234/234 [02:41<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.54it/s]\n",
      "                   all        977       1170      0.923       0.96      0.957       0.63\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/49      11.4G    0.02974     0.0104  0.0007959         30        640: 100% 234/234 [02:39<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:19<00:00,  1.55it/s]\n",
      "                   all        977       1170      0.919      0.962      0.955      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/49      11.4G    0.02949    0.01025  0.0005958         36        640: 100% 234/234 [02:42<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.55it/s]\n",
      "                   all        977       1170      0.942      0.964      0.969      0.646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/49      11.4G    0.02885    0.01019  0.0005312         31        640: 100% 234/234 [02:39<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.55it/s]\n",
      "                   all        977       1170      0.919      0.975      0.962      0.651\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/49      11.4G    0.02783    0.01011  0.0005057         25        640: 100% 234/234 [02:46<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.54it/s]\n",
      "                   all        977       1170      0.931      0.963      0.963      0.656\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/49      11.4G    0.02751   0.009945  0.0006728         42        640: 100% 234/234 [02:44<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:21<00:00,  1.43it/s]\n",
      "                   all        977       1170      0.928      0.962      0.954      0.646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/49      11.4G    0.02637   0.009716  0.0003624         33        640: 100% 234/234 [02:45<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.52it/s]\n",
      "                   all        977       1170       0.94      0.959      0.963      0.664\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/49      11.4G    0.02654   0.009972   0.000495         24        640: 100% 234/234 [02:42<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.53it/s]\n",
      "                   all        977       1170      0.932      0.973      0.972       0.67\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/49      11.4G    0.02593   0.009572  0.0004254         22        640: 100% 234/234 [02:38<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.51it/s]\n",
      "                   all        977       1170      0.935      0.983      0.969      0.663\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/49      11.4G    0.02519   0.009399  0.0003744         30        640: 100% 234/234 [02:41<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.49it/s]\n",
      "                   all        977       1170      0.935      0.966      0.969      0.676\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/49      11.4G    0.02548   0.009277   0.000366         29        640: 100% 234/234 [02:39<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:19<00:00,  1.55it/s]\n",
      "                   all        977       1170      0.927      0.979      0.971      0.679\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      20/49      11.4G    0.02528    0.00916  0.0004402         23        640: 100% 234/234 [02:43<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:19<00:00,  1.57it/s]\n",
      "                   all        977       1170      0.932      0.974      0.967      0.665\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      21/49      11.4G     0.0247   0.009268  0.0003291         27        640: 100% 234/234 [02:38<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:19<00:00,  1.55it/s]\n",
      "                   all        977       1170      0.945      0.955      0.968      0.676\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      22/49      11.4G    0.02413   0.009158  0.0003702         28        640: 100% 234/234 [02:42<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:19<00:00,  1.55it/s]\n",
      "                   all        977       1170      0.949      0.961      0.965      0.669\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      23/49      11.4G    0.02423    0.00927  0.0004388         25        640: 100% 234/234 [02:39<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.53it/s]\n",
      "                   all        977       1170      0.942      0.969      0.972      0.674\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      24/49      11.4G    0.02368   0.008946  0.0003675         39        640: 100% 234/234 [02:41<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.49it/s]\n",
      "                   all        977       1170       0.94      0.965      0.966      0.675\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      25/49      11.4G    0.02349   0.008672  0.0003133         36        640: 100% 234/234 [02:40<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.52it/s]\n",
      "                   all        977       1170      0.951      0.965      0.971      0.673\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      26/49      11.4G    0.02293   0.008715  0.0002466         44        640: 100% 234/234 [02:42<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.53it/s]\n",
      "                   all        977       1170       0.95      0.973       0.97      0.686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      27/49      11.4G    0.02264   0.008601  0.0002371         26        640: 100% 234/234 [02:40<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:19<00:00,  1.55it/s]\n",
      "                   all        977       1170      0.951      0.963      0.974      0.686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      28/49      11.4G    0.02259   0.008743   0.000247         44        640: 100% 234/234 [02:46<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.54it/s]\n",
      "                   all        977       1170      0.944      0.982      0.977      0.699\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      29/49      11.4G    0.02235   0.008495  0.0001768         40        640: 100% 234/234 [02:38<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.50it/s]\n",
      "                   all        977       1170      0.943      0.977      0.977      0.698\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      30/49      11.4G    0.02213   0.008492  0.0001867         33        640: 100% 234/234 [02:41<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.52it/s]\n",
      "                   all        977       1170      0.952      0.968      0.976      0.689\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      31/49      11.4G     0.0219   0.008306  0.0001986         34        640: 100% 234/234 [02:38<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.51it/s]\n",
      "                   all        977       1170      0.953      0.967      0.972       0.69\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      32/49      11.4G    0.02152   0.008388  0.0002145         37        640: 100% 234/234 [02:40<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.53it/s]\n",
      "                   all        977       1170      0.953      0.969      0.973      0.695\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      33/49      11.4G    0.02127   0.008312  0.0002074         44        640: 100% 234/234 [02:38<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.52it/s]\n",
      "                   all        977       1170       0.96      0.966      0.972        0.7\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      34/49      11.4G    0.02128   0.008172  0.0002577         31        640: 100% 234/234 [02:41<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.51it/s]\n",
      "                   all        977       1170      0.959      0.966      0.971      0.703\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      35/49      11.4G     0.0208   0.008097  0.0001747         39        640: 100% 234/234 [02:40<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:19<00:00,  1.55it/s]\n",
      "                   all        977       1170       0.95      0.976      0.973      0.694\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      36/49      11.4G    0.02037   0.007825  0.0002081         34        640: 100% 234/234 [02:42<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:19<00:00,  1.56it/s]\n",
      "                   all        977       1170      0.959      0.951      0.969      0.692\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      37/49      11.4G    0.02024   0.007584  0.0001494         32        640: 100% 234/234 [02:38<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.48it/s]\n",
      "                   all        977       1170      0.959      0.963      0.969      0.699\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      38/49      11.4G    0.01995   0.007836   0.000116         34        640: 100% 234/234 [02:43<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:19<00:00,  1.55it/s]\n",
      "                   all        977       1170       0.96      0.966      0.973      0.701\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      39/49      11.4G    0.01967    0.00782  0.0001749         35        640: 100% 234/234 [02:39<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:19<00:00,  1.55it/s]\n",
      "                   all        977       1170      0.954      0.968      0.972      0.699\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      40/49      11.4G    0.01945   0.007535  0.0001653         25        640: 100% 234/234 [02:42<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:19<00:00,  1.55it/s]\n",
      "                   all        977       1170      0.958      0.955      0.976      0.693\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      41/49      11.4G      0.019   0.007486  0.0001213         35        640: 100% 234/234 [02:39<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:19<00:00,  1.56it/s]\n",
      "                   all        977       1170      0.965      0.961      0.974      0.704\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      42/49      11.4G     0.0193    0.00737  0.0001422         38        640: 100% 234/234 [02:42<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:21<00:00,  1.47it/s]\n",
      "                   all        977       1170      0.964      0.952      0.965      0.689\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      43/49      11.4G    0.01883   0.007346  0.0001128         30        640: 100% 234/234 [02:39<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.50it/s]\n",
      "                   all        977       1170       0.96      0.969      0.976        0.7\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      44/49      11.4G    0.01861    0.00753  0.0001078         32        640: 100% 234/234 [02:41<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.53it/s]\n",
      "                   all        977       1170      0.959      0.971       0.97      0.698\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      45/49      11.4G     0.0185   0.007422  0.0001174         35        640: 100% 234/234 [02:39<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.53it/s]\n",
      "                   all        977       1170      0.963      0.958      0.973      0.699\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      46/49      11.4G    0.01815   0.007133  7.641e-05         38        640: 100% 234/234 [02:42<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.49it/s]\n",
      "                   all        977       1170      0.951      0.967      0.971      0.703\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      47/49      11.4G    0.01771   0.007045   0.000104         34        640: 100% 234/234 [02:39<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.49it/s]\n",
      "                   all        977       1170      0.961      0.955      0.965      0.699\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      48/49      11.4G    0.01754   0.007009  6.334e-05         40        640: 100% 234/234 [02:43<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.54it/s]\n",
      "                   all        977       1170      0.958      0.961      0.969      0.703\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      49/49      11.4G    0.01746    0.00702  7.925e-05         39        640: 100% 234/234 [02:40<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:20<00:00,  1.52it/s]\n",
      "                   all        977       1170      0.961      0.957      0.968      0.704\n",
      "\n",
      "50 epochs completed in 2.576 hours.\n",
      "Optimizer stripped from ../camera_dedects/results/weights/last.pt, 92.9MB\n",
      "Optimizer stripped from ../camera_dedects/results/weights/best.pt, 92.9MB\n",
      "\n",
      "Validating ../camera_dedects/results/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 267 layers, 46113663 parameters, 0 gradients, 107.7 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 31/31 [00:22<00:00,  1.37it/s]\n",
      "                   all        977       1170      0.965      0.961      0.974      0.704\n",
      "             guide dog        977        262      0.946      0.938      0.955      0.683\n",
      "             whiteCane        977        908      0.985      0.983      0.992      0.725\n",
      "Results saved to \u001b[1m../camera_dedects/results\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "# 옵션\n",
    "# img: 이미지 크기, batch: 일괄 처리할 양, epochs: 반복 횟수, data: yaml파일의 위치, weights: 사전학습된 yolo모델, project, name: 학습 완료 모델 저장경로 지정\n",
    "!python train.py --img 640 --batch 16  --epochs 50 --data /content/blind-man-13/data.yaml --weights yolov5l.pt --project ../camera_dedects --name results --exist-ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1704086114519,
     "user": {
      "displayName": "윤동언",
      "userId": "18223722253991517958"
     },
     "user_tz": -540
    },
    "id": "9Ohi3p2UYZdY"
   },
   "outputs": [],
   "source": [
    "TEST_VIDEO_PATH = \"/content/drive/MyDrive/blind_man/blind_vid1.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15691,
     "status": "ok",
     "timestamp": 1704086320210,
     "user": {
      "displayName": "윤동언",
      "userId": "18223722253991517958"
     },
     "user_tz": -540
    },
    "id": "vPtMhrOcbnsd",
    "outputId": "49058752-675a-4a0a-a86f-b910ee65602f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/camera_dedects/results/weights/best.pt'], source=/content/drive/MyDrive/blind_man/blind_vid1.mp4, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.3, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=/content/, name=result_image, exist_ok=True, line_thickness=4, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 🚀 v7.0-254-gba63208 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 267 layers, 46113663 parameters, 0 gradients, 107.7 GFLOPs\n",
      "video 1/1 (1/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 55.9ms\n",
      "video 1/1 (2/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 31.9ms\n",
      "video 1/1 (3/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 31.9ms\n",
      "video 1/1 (4/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 31.9ms\n",
      "video 1/1 (5/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 32.0ms\n",
      "video 1/1 (6/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 26.1ms\n",
      "video 1/1 (7/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 20.3ms\n",
      "video 1/1 (8/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 1 whiteCane, 20.3ms\n",
      "video 1/1 (9/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 20.4ms\n",
      "video 1/1 (10/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 20.4ms\n",
      "video 1/1 (11/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 20.4ms\n",
      "video 1/1 (12/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 20.4ms\n",
      "video 1/1 (13/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 1 whiteCane, 20.4ms\n",
      "video 1/1 (14/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 20.3ms\n",
      "video 1/1 (15/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 20.3ms\n",
      "video 1/1 (16/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.4ms\n",
      "video 1/1 (17/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.3ms\n",
      "video 1/1 (18/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.4ms\n",
      "video 1/1 (19/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.7ms\n",
      "video 1/1 (20/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.2ms\n",
      "video 1/1 (21/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.5ms\n",
      "video 1/1 (22/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.4ms\n",
      "video 1/1 (23/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 14.9ms\n",
      "video 1/1 (24/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.6ms\n",
      "video 1/1 (25/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.1ms\n",
      "video 1/1 (26/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 14.9ms\n",
      "video 1/1 (27/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.1ms\n",
      "video 1/1 (28/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.5ms\n",
      "video 1/1 (29/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 14.9ms\n",
      "video 1/1 (30/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.9ms\n",
      "video 1/1 (31/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.0ms\n",
      "video 1/1 (32/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.2ms\n",
      "video 1/1 (33/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.1ms\n",
      "video 1/1 (34/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.2ms\n",
      "video 1/1 (35/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.8ms\n",
      "video 1/1 (36/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.1ms\n",
      "video 1/1 (37/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.3ms\n",
      "video 1/1 (38/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.5ms\n",
      "video 1/1 (39/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.0ms\n",
      "video 1/1 (40/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 1 whiteCane, 15.1ms\n",
      "video 1/1 (41/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 1 whiteCane, 15.5ms\n",
      "video 1/1 (42/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 1 whiteCane, 15.5ms\n",
      "video 1/1 (43/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 1 whiteCane, 14.8ms\n",
      "video 1/1 (44/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 1 whiteCane, 15.8ms\n",
      "video 1/1 (45/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 1 whiteCane, 15.4ms\n",
      "video 1/1 (46/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.1ms\n",
      "video 1/1 (47/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.8ms\n",
      "video 1/1 (48/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.5ms\n",
      "video 1/1 (49/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 14.9ms\n",
      "video 1/1 (50/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.6ms\n",
      "video 1/1 (51/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.1ms\n",
      "video 1/1 (52/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.2ms\n",
      "video 1/1 (53/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.7ms\n",
      "video 1/1 (54/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.1ms\n",
      "video 1/1 (55/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.5ms\n",
      "video 1/1 (56/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.0ms\n",
      "video 1/1 (57/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.8ms\n",
      "video 1/1 (58/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.2ms\n",
      "video 1/1 (59/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.5ms\n",
      "video 1/1 (60/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.1ms\n",
      "video 1/1 (61/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 1 whiteCane, 16.6ms\n",
      "video 1/1 (62/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 1 whiteCane, 15.7ms\n",
      "video 1/1 (63/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 1 whiteCane, 15.1ms\n",
      "video 1/1 (64/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.5ms\n",
      "video 1/1 (65/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 14.9ms\n",
      "video 1/1 (66/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.8ms\n",
      "video 1/1 (67/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.1ms\n",
      "video 1/1 (68/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.4ms\n",
      "video 1/1 (69/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.1ms\n",
      "video 1/1 (70/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.4ms\n",
      "video 1/1 (71/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.5ms\n",
      "video 1/1 (72/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.7ms\n",
      "video 1/1 (73/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.4ms\n",
      "video 1/1 (74/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 14.9ms\n",
      "video 1/1 (75/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.2ms\n",
      "video 1/1 (76/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.3ms\n",
      "video 1/1 (77/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.4ms\n",
      "video 1/1 (78/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.4ms\n",
      "video 1/1 (79/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.0ms\n",
      "video 1/1 (80/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.4ms\n",
      "video 1/1 (81/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.5ms\n",
      "video 1/1 (82/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 20.3ms\n",
      "video 1/1 (83/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.1ms\n",
      "video 1/1 (84/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.6ms\n",
      "video 1/1 (85/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.3ms\n",
      "video 1/1 (86/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.1ms\n",
      "video 1/1 (87/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.2ms\n",
      "video 1/1 (88/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.5ms\n",
      "video 1/1 (89/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.1ms\n",
      "video 1/1 (90/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.5ms\n",
      "video 1/1 (91/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.5ms\n",
      "video 1/1 (92/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.0ms\n",
      "video 1/1 (93/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.2ms\n",
      "video 1/1 (94/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.5ms\n",
      "video 1/1 (95/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.0ms\n",
      "video 1/1 (96/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.1ms\n",
      "video 1/1 (97/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.6ms\n",
      "video 1/1 (98/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 14.9ms\n",
      "video 1/1 (99/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.6ms\n",
      "video 1/1 (100/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.8ms\n",
      "video 1/1 (101/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.1ms\n",
      "video 1/1 (102/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.2ms\n",
      "video 1/1 (103/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.4ms\n",
      "video 1/1 (104/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.8ms\n",
      "video 1/1 (105/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.0ms\n",
      "video 1/1 (106/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.9ms\n",
      "video 1/1 (107/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.1ms\n",
      "video 1/1 (108/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.5ms\n",
      "video 1/1 (109/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.0ms\n",
      "video 1/1 (110/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.4ms\n",
      "video 1/1 (111/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.1ms\n",
      "video 1/1 (112/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.2ms\n",
      "video 1/1 (113/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.3ms\n",
      "video 1/1 (114/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.2ms\n",
      "video 1/1 (115/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.8ms\n",
      "video 1/1 (116/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.1ms\n",
      "video 1/1 (117/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.4ms\n",
      "video 1/1 (118/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.6ms\n",
      "video 1/1 (119/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.3ms\n",
      "video 1/1 (120/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.4ms\n",
      "video 1/1 (121/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 1 guide dog, 15.9ms\n",
      "video 1/1 (122/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 1 guide dog, 15.8ms\n",
      "video 1/1 (123/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 1 guide dog, 15.2ms\n",
      "video 1/1 (124/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 1 guide dog, 15.4ms\n",
      "video 1/1 (125/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.6ms\n",
      "video 1/1 (126/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 14.9ms\n",
      "video 1/1 (127/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.9ms\n",
      "video 1/1 (128/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.8ms\n",
      "video 1/1 (129/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.0ms\n",
      "video 1/1 (130/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.2ms\n",
      "video 1/1 (131/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.8ms\n",
      "video 1/1 (132/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.1ms\n",
      "video 1/1 (133/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.2ms\n",
      "video 1/1 (134/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.1ms\n",
      "video 1/1 (135/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.4ms\n",
      "video 1/1 (136/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.0ms\n",
      "video 1/1 (137/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.3ms\n",
      "video 1/1 (138/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.9ms\n",
      "video 1/1 (139/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.5ms\n",
      "video 1/1 (140/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.0ms\n",
      "video 1/1 (141/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.2ms\n",
      "video 1/1 (142/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.6ms\n",
      "video 1/1 (143/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.0ms\n",
      "video 1/1 (144/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.3ms\n",
      "video 1/1 (145/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.8ms\n",
      "video 1/1 (146/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.0ms\n",
      "video 1/1 (147/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.2ms\n",
      "video 1/1 (148/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.6ms\n",
      "video 1/1 (149/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.9ms\n",
      "video 1/1 (150/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.1ms\n",
      "video 1/1 (151/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.4ms\n",
      "video 1/1 (152/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.6ms\n",
      "video 1/1 (153/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.2ms\n",
      "video 1/1 (154/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.4ms\n",
      "video 1/1 (155/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.3ms\n",
      "video 1/1 (156/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.2ms\n",
      "video 1/1 (157/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.7ms\n",
      "video 1/1 (158/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 19.4ms\n",
      "video 1/1 (159/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.3ms\n",
      "video 1/1 (160/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 14.9ms\n",
      "video 1/1 (161/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.3ms\n",
      "video 1/1 (162/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.6ms\n",
      "video 1/1 (163/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.0ms\n",
      "video 1/1 (164/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.1ms\n",
      "video 1/1 (165/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.3ms\n",
      "video 1/1 (166/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.4ms\n",
      "video 1/1 (167/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.9ms\n",
      "video 1/1 (168/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.0ms\n",
      "video 1/1 (169/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.6ms\n",
      "video 1/1 (170/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.2ms\n",
      "video 1/1 (171/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.5ms\n",
      "video 1/1 (172/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.0ms\n",
      "video 1/1 (173/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.0ms\n",
      "video 1/1 (174/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.3ms\n",
      "video 1/1 (175/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.5ms\n",
      "video 1/1 (176/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.2ms\n",
      "video 1/1 (177/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.4ms\n",
      "video 1/1 (178/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.7ms\n",
      "video 1/1 (179/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.0ms\n",
      "video 1/1 (180/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.8ms\n",
      "video 1/1 (181/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.6ms\n",
      "video 1/1 (182/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.0ms\n",
      "video 1/1 (183/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.6ms\n",
      "video 1/1 (184/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.3ms\n",
      "video 1/1 (185/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.5ms\n",
      "video 1/1 (186/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.2ms\n",
      "video 1/1 (187/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.4ms\n",
      "video 1/1 (188/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.8ms\n",
      "video 1/1 (189/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.1ms\n",
      "video 1/1 (190/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.8ms\n",
      "video 1/1 (191/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.0ms\n",
      "video 1/1 (192/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.3ms\n",
      "video 1/1 (193/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.3ms\n",
      "video 1/1 (194/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.1ms\n",
      "video 1/1 (195/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.4ms\n",
      "video 1/1 (196/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.7ms\n",
      "video 1/1 (197/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 19.5ms\n",
      "video 1/1 (198/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.1ms\n",
      "video 1/1 (199/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 14.9ms\n",
      "video 1/1 (200/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 14.8ms\n",
      "video 1/1 (201/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.3ms\n",
      "video 1/1 (202/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.7ms\n",
      "video 1/1 (203/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.0ms\n",
      "video 1/1 (204/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.5ms\n",
      "video 1/1 (205/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.8ms\n",
      "video 1/1 (206/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.1ms\n",
      "video 1/1 (207/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.3ms\n",
      "video 1/1 (208/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.5ms\n",
      "video 1/1 (209/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.4ms\n",
      "video 1/1 (210/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.9ms\n",
      "video 1/1 (211/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.2ms\n",
      "video 1/1 (212/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.6ms\n",
      "video 1/1 (213/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.1ms\n",
      "video 1/1 (214/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.2ms\n",
      "video 1/1 (215/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.4ms\n",
      "video 1/1 (216/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.3ms\n",
      "video 1/1 (217/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.5ms\n",
      "video 1/1 (218/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.2ms\n",
      "video 1/1 (219/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.3ms\n",
      "video 1/1 (220/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.4ms\n",
      "video 1/1 (221/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.3ms\n",
      "video 1/1 (222/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.8ms\n",
      "video 1/1 (223/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.3ms\n",
      "video 1/1 (224/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.0ms\n",
      "video 1/1 (225/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 16.0ms\n",
      "video 1/1 (226/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.9ms\n",
      "video 1/1 (227/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.6ms\n",
      "video 1/1 (228/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.1ms\n",
      "video 1/1 (229/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 14.9ms\n",
      "video 1/1 (230/230) /content/drive/MyDrive/blind_man/blind_vid1.mp4: 384x640 (no detections), 15.5ms\n",
      "Speed: 0.5ms pre-process, 16.4ms inference, 2.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1m/content/result_image\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --source '{TEST_VIDEO_PATH}'  --weights /content/camera_dedects/results/weights/best.pt  --img 640  --conf 0.3 --project /content/ --name=result_image --exist-ok --line-thickness 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1704086322328,
     "user": {
      "displayName": "윤동언",
      "userId": "18223722253991517958"
     },
     "user_tz": -540
    },
    "id": "U61gLZ5obyOo"
   },
   "outputs": [],
   "source": [
    "detect_video = '/content/result_image/blind_vid1.mp4' # 경로 수정\n",
    "\n",
    "# 비디오 데이터 압축 (Colab에서 실행 목적)\n",
    "def video_compressing(detect_video):\n",
    "  compressed_video = detect_video[:-4] + \"_compressed.mp4\"\n",
    "  os.system(f\"ffmpeg -i {detect_video} -vcodec libx264 {compressed_video}\")\n",
    "\n",
    "  return compressed_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245,
     "output_embedded_package_id": "1EbdQCruQnmWQ9f6tYaXAceYKOGywX5_s"
    },
    "executionInfo": {
     "elapsed": 1907,
     "status": "ok",
     "timestamp": 1704086326072,
     "user": {
      "displayName": "윤동언",
      "userId": "18223722253991517958"
     },
     "user_tz": -540
    },
    "id": "C5lgDqnWb07Z",
    "outputId": "58a9a7f0-18ec-49c8-b117-82242cb24032"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "compressed_video = video_compressing(detect_video)\n",
    "\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "mp4 = open(compressed_video,'rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(\"\"\"\n",
    "<video width=400 controls>\n",
    "    <source src=\"%s\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\" % data_url)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
